# Module 16 Challenge: Amazon Vine Analysis

## Overview

The task for this project is to analyze Amazon Reviews written by both paid (via Amazon Vine Program) and unpaid customers to determine if there is a bias towards favorable reviews published by paid Vine members. The product dataset type I selected for my analysis was watches.

The specific steps to complete this project are as follows: use PySpark to perform the ETL process to extract the dataset, transform the data, connect to an AWS RDS instance, and load the transformed data into pgAdmin, use PySpark, Pandas, or SQL to determine if there is any bias.

## Results

### Total Number of Reviews
**8,409**

### Total Number of 5 Star Reviews
**4,347**
![totals](https://user-images.githubusercontent.com/88041368/142890109-6f799bf7-c6f6-4f15-a1f7-cf0eac93fbd7.jpg)
### Percentage of 5 Star Reviews that are from Vine (Paid)
**0.003450655624568668**

### Percentage of 5 Star Reviews that are NOT from Vine (Unpaid)
**0.9965493443754313**
![results](https://user-images.githubusercontent.com/88041368/142890105-8d4b0ab2-35e9-45d3-85c6-070ec4629b3d.jpg)
*Additional screen grab to show the rest of the code blocks*
![Results_cont](https://user-images.githubusercontent.com/88041368/142890107-116e13db-93d1-41da-b64f-50d1480488bd.jpg)
### pgAdmin Data Tables Generated by Loading Data Frames created via PySpark in Google Colab to AWS SQL Database:
![Customers_Table](https://user-images.githubusercontent.com/88041368/142887105-042d988d-dc1f-4c32-96f6-671faf2cbd6c.jpg)
![Products_Table](https://user-images.githubusercontent.com/88041368/142887108-3e95c998-6a0d-4a30-9241-65e5fd8a9494.jpg)
![Review_ID_Table](https://user-images.githubusercontent.com/88041368/142887113-3e9d09a0-b9b8-41ca-9ef6-56040159afb6.jpg)
![Vine_Table](https://user-images.githubusercontent.com/88041368/142887115-b70fb9e3-007b-4c84-bc88-c88dba31649d.jpg)

## Summary
Unfortunately, the sample size of paid, vine reviews was very small compared to the sample of unpaid reviews. Only **47** vine reviews were available compared to the **8,362** unpaid reviews.

A more effective way to measure if there may be bias is to compare the percentage of each star count for the paid and unpaid samples. Additional data analysis was conducted:

Unpaid Review Results:
5 Stars = 52%
4 Stars = 16%
3 Stars = 9%
2 Stars = 6%
1 Star = 17%

Paid Review Results:
5 Stars = 32%
4 Stars = 43%
3 Stars = 15%
2 Stars = 6%
1 Star = 4%

Interestingly, the largest percentage of ratings for unpaid reviews was 5 stars whereas 4 stars was the largest for the paid members. However, it also appears more likely that an unpaid reviewer would leave a 1 star review than a paid reviewer would. Based on this limited sample, we could say that there doesnâ€™t appear to be a bias towards paid reviewers rating watches with 5 star reviews but there is far less likelihood that they would leave a 1 star review compared to the unpaid reviewers.

